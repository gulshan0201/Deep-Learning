{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights are [0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def perceptron(x,wt):\n",
    "    f=0\n",
    "    for i,w in zip(x,wt):\n",
    "        f+=w*i\n",
    "    if f>=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "x=[5,0.2]\n",
    "#wt=[-1,1]\n",
    "wt=random.sample(range(-1, 2), 2) \n",
    "print('Random Weights are',wt)\n",
    "perceptron(x,wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights are [3, 1, -1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def perceptron(x,wt):\n",
    "    f=0\n",
    "    for i,w in zip(x,wt):\n",
    "        w=w/10\n",
    "        f+=w*i\n",
    "    if f>=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "x=[7.8,2,2,0.5]\n",
    "#wt=[1,1,0,1]\n",
    "wt=random.sample(range(-1, 4), 4) \n",
    "print('Random Weights are',wt)\n",
    "\n",
    "perceptron(x,wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x classified as = 1 \n",
      "\n",
      "Random Weights are [1, -1]\n",
      "correctly classified\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def perceptron(x,wt):\n",
    "    f=0\n",
    "    for i,w in zip(x,wt):\n",
    "        f+=w*i\n",
    "    if f>=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "x=[5,0.2,1]\n",
    "print(\"x classified as =\",x[2],\"\\n\")\n",
    "#wt=[1,-1]\n",
    "wt=random.sample(range(-1, 2), 2) \n",
    "print('Random Weights are',wt)\n",
    "cls=perceptron(x,wt)\n",
    "if cls==x[2]:\n",
    "    print(\"correctly classified\")\n",
    "else:\n",
    "    print(\"Incorrectly classified\")\n",
    "    cls=perceptron(x,wt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with weights\n",
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    "\n",
    "# test predictions of action and horror features\n",
    "dataset = [[2,2,0],\n",
    "    [1,2,0],\n",
    "    [5,4,1],\n",
    "    [2,1,0],\n",
    "    [3,3,1],\n",
    "    [7,2,1],\n",
    "    [5,2,1],\n",
    "    [6,1,1],\n",
    "    [8,-0.2,1],\n",
    "    [7,3,1]]\n",
    "weights = [-0.4, 0.09999999999999992, 0.10000000000000003]\n",
    "for row in dataset:\n",
    "    prediction = predict(row, weights)\n",
    "    print(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extimate weights with Schocastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">turn=0, lrate=0.100, error=3.000\n",
      ">turn=1, lrate=0.100, error=3.000\n",
      ">turn=2, lrate=0.100, error=3.000\n",
      ">turn=3, lrate=0.100, error=1.000\n",
      "[-0.4, 0.09999999999999992, 0.10000000000000003]\n",
      "Expected=0, Predicted=0\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with wt; Extimate weights with Stochastic gradient descent\n",
    "def predict(row, wt):\n",
    "    activation = wt[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += wt[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    " \n",
    "# Estimate Perceptron wt using stochastic gradient descent\n",
    "def train_wt(train, l_rate, n_turn):\n",
    "    wt = [0.0 for i in range(len(train[0]))]\n",
    "    for turn in range(n_turn):\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            prediction = predict(row, wt)\n",
    "            error = row[-1] - prediction\n",
    "            sum_error += error**2\n",
    "            wt[0] = wt[0] + l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                wt[i + 1] = wt[i + 1] + l_rate * error * row[i]\n",
    "        print('>turn=%d, lrate=%.3f, error=%.3f' % (turn, l_rate, sum_error))\n",
    "    return wt\n",
    " \n",
    "# Calculate wt\n",
    "dataset = [[2,2,0],\n",
    "    [1,2,0],\n",
    "    [5,4,1],\n",
    "    [2,1,0],\n",
    "    [3,3,1],\n",
    "    [7,2,1],\n",
    "    [5,2,1],\n",
    "    [6,1,1],\n",
    "    [8,-0.2,1],\n",
    "    [7,3,1]]\n",
    "l_rate = 0.1\n",
    "n_turn = 4\n",
    "wt = train_wt(dataset, l_rate, n_turn)\n",
    "print(wt)\n",
    "for row in dataset:\n",
    "    prediction = predict(row, wt)\n",
    "    print(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward network with multiple neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective \n",
    "### Add a hidden layers\n",
    "\n",
    "### Use continuous activation functions (sigmoid / ReLU)\n",
    "\n",
    "### Perform forward propagation through layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of sigmoidal Activation Function\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the output of single unit (neuron)\n",
    "def neuron_output(weights, inputs):\n",
    "    activation = weights[0]  # bias\n",
    "    for i in range(len(inputs)):\n",
    "        activation += weights[i + 1] * inputs[i]\n",
    "    return sigmoid(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(ffnet_layers, row):\n",
    "    inputs = row[:-1]   # exclude label\n",
    "    print('input:',row)\n",
    "    for layer in ffnet_layers:\n",
    "        new_inputs = []\n",
    "        i = 0;\n",
    "        \n",
    "        for neuron in layer:\n",
    "            output = neuron_output(neuron, inputs)\n",
    "            new_inputs.append(output)\n",
    "            \n",
    "        inputs = new_inputs\n",
    "    \n",
    "\n",
    "    return inputs[0]    # final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Feed Forward Network (ffnet) with one hidded layer having two neurons and outlayer with one neuron.\n",
    "ffnet_layers = [\n",
    "    [   # input layer to Hidden layer\n",
    "        [0.1, 0.2, -0.3],   # neuron 1: bias, w1, w2\n",
    "        [-0.1, 0.4, 0.1]    # neuron 2: bias, w1, w2\n",
    "    ],\n",
    "    [   # hidden layer to Output layer\n",
    "        [0.05, 0.3, -0.2]   # bias, w_hidden1, w_hidden2\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    [1,2,0],\n",
    "    [5,4,1],\n",
    "    [2,1,0],\n",
    "    [3,3,1],\n",
    "    [7,2,1],\n",
    "    [5,2,1],\n",
    "    [6,1,1],\n",
    "    [8,-0.2,1],\n",
    "    [7,3,1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [1, 2, 0]\n",
      "Expected=0, Predicted=1, Output=0.513\n",
      "input: [5, 4, 1]\n",
      "Expected=1, Predicted=1, Output=0.503\n",
      "input: [2, 1, 0]\n",
      "Expected=0, Predicted=1, Output=0.519\n",
      "input: [3, 3, 1]\n",
      "Expected=1, Predicted=1, Output=0.506\n",
      "input: [7, 2, 1]\n",
      "Expected=1, Predicted=1, Output=0.518\n",
      "input: [5, 2, 1]\n",
      "Expected=1, Predicted=1, Output=0.515\n",
      "input: [6, 1, 1]\n",
      "Expected=1, Predicted=1, Output=0.521\n",
      "input: [8, -0.2, 1]\n",
      "Expected=1, Predicted=1, Output=0.529\n",
      "input: [7, 3, 1]\n",
      "Expected=1, Predicted=1, Output=0.513\n"
     ]
    }
   ],
   "source": [
    "for row in dataset:\n",
    "    output = forward_propagate(ffnet_layers, row)\n",
    "    prediction = 1 if output >= 0.5 else 0\n",
    "    print(f\"Expected={row[-1]}, Predicted={prediction}, Output={output:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate sgd based training with Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define acrtivation function\n",
    "import math\n",
    "import random\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise network parameters\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = []\n",
    "\n",
    "    hidden_layer = []\n",
    "    for _ in range(n_hidden):\n",
    "        neuron = {\n",
    "            'weights': [random.uniform(-0.5, 0.5) for _ in range(n_inputs + 1)]\n",
    "        }\n",
    "        hidden_layer.append(neuron)\n",
    "    network.append(hidden_layer)\n",
    "\n",
    "    output_layer = []\n",
    "    for _ in range(n_outputs):\n",
    "        neuron = {\n",
    "            'weights': [random.uniform(-0.5, 0.5) for _ in range(n_hidden + 1)]\n",
    "        }\n",
    "        output_layer.append(neuron)\n",
    "    network.append(output_layer)\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propagation\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row[:-1]\n",
    "\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = neuron['weights'][0]  # bias\n",
    "            for i in range(len(inputs)):\n",
    "                activation += neuron['weights'][i + 1] * inputs[i]\n",
    "            neuron['output'] = sigmoid(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Propagation\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = []\n",
    "\n",
    "        if i == len(network) - 1:  # output layer\n",
    "            for j, neuron in enumerate(layer):\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        else:  # hidden layer\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += neuron['weights'][j + 1] * neuron['delta']\n",
    "                errors.append(error)\n",
    "\n",
    "        for j, neuron in enumerate(layer):\n",
    "            neuron['delta'] = errors[j] * sigmoid_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight updation with sgd\n",
    "def update_weights(network, row, l_rate):\n",
    "    inputs = row[:-1]\n",
    "\n",
    "    for i, layer in enumerate(network):\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\n",
    "        for neuron in layer:\n",
    "            neuron['weights'][0] += l_rate * neuron['delta']  # bias\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j + 1] += l_rate * neuron['delta'] * inputs[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with sgd\n",
    "def train_network(network, train, l_rate, n_epoch):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [row[-1]]\n",
    "            sum_error += (expected[0] - outputs[0]) ** 2\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print(f\"Epoch={epoch}, Error={sum_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, row):\n",
    "    output = forward_propagate(network, row)[0]\n",
    "    return 1 if output >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Error=1.6567\n",
      "Epoch=1, Error=1.5959\n",
      "Epoch=2, Error=1.5595\n",
      "Epoch=3, Error=1.5367\n",
      "Epoch=4, Error=1.5214\n",
      "Epoch=5, Error=1.5106\n",
      "Epoch=6, Error=1.5024\n",
      "Epoch=7, Error=1.4958\n",
      "Epoch=8, Error=1.4902\n",
      "Epoch=9, Error=1.4851\n",
      "Epoch=10, Error=1.4804\n",
      "Epoch=11, Error=1.4760\n",
      "Epoch=12, Error=1.4716\n",
      "Epoch=13, Error=1.4673\n",
      "Epoch=14, Error=1.4629\n",
      "Expected=0, Output=0.741, Predicted=1\n",
      "Expected=1, Output=0.787, Predicted=1\n",
      "Expected=0, Output=0.767, Predicted=1\n",
      "Expected=1, Output=0.768, Predicted=1\n",
      "Expected=1, Output=0.802, Predicted=1\n",
      "Expected=1, Output=0.793, Predicted=1\n",
      "Expected=1, Output=0.800, Predicted=1\n",
      "Expected=1, Output=0.805, Predicted=1\n",
      "Expected=1, Output=0.800, Predicted=1\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "dataset = [\n",
    "    [1,2,0],\n",
    "    [5,4,1],\n",
    "    [2,1,0],\n",
    "    [3,3,1],\n",
    "    [7,2,1],\n",
    "    [5,2,1],\n",
    "    [6,1,1],\n",
    "    [8,-0.2,1],\n",
    "    [7,3,1]\n",
    "]\n",
    "\n",
    "network = initialize_network(2, 2, 1)\n",
    "\n",
    "train_network(network, dataset, l_rate=0.3, n_epoch=15)\n",
    "\n",
    "for row in dataset:\n",
    "    output = forward_propagate(network, row)[0]\n",
    "    prediction = predict(network, row)\n",
    "    print(f\"Expected={row[-1]}, Output={output:.3f}, Predicted={prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Neural Network with Keras with SGD and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([\n",
    "    [2, 2, 0],\n",
    "    [1, 2, 0],\n",
    "    [5, 4, 1],\n",
    "    [2, 1, 0],\n",
    "    [3, 3, 1],\n",
    "    [7, 2, 1],\n",
    "    [5, 2, 1],\n",
    "    [6, 1, 1],\n",
    "    [8, -0.2, 1],\n",
    "    [7, 3, 1]\n",
    "], dtype=float)\n",
    "\n",
    "X = dataset[:, :-1]   # inputs\n",
    "y = dataset[:, -1]    # labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split FIRST\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward Neural Network\n",
    "model = Sequential([\n",
    "    Dense(2, activation='sigmoid', input_shape=(2,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training \n",
    "history = model.fit(X_train, y_train, epochs=500, verbose=0)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=1, Predicted=1\n",
      "Expected=0, Predicted=0\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"Expected={int(y_test[i])}, Predicted={pred[i][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT Dataset (Binary Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using pandas\n",
    "\n",
    "data = pd.read_csv(\"iot_dataset.csv\")\n",
    "\n",
    "# Assume last column is label\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values   # 0 = Normal, 1 = Attack\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape for CNN (samples, features, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test  = X_test.reshape(X_test.shape[0],  X_test.shape[1],  1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolution Layer\n",
    "model.add(Conv1D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# 2nd Convolution Layer\n",
    "model.add(Conv1D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:251 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 2, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b40cdc410057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Suresh\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:251 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to CNN: (1, 64, 64, 3)\n",
      "Image shape: (1, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load image\n",
    "img = load_img(\"100.jpg\", target_size=(64, 64))  # RGB by default\n",
    "img_array = img_to_array(img)\n",
    "# Add batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "print(\"Input shape to CNN:\", img_array.shape)\n",
    "\n",
    "print(\"Image shape:\", img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[196. 185. 181.]\n",
      "   [190. 179. 175.]\n",
      "   [190. 176. 173.]\n",
      "   ...\n",
      "   [ 43.  30.  21.]\n",
      "   [ 48.  31.  21.]\n",
      "   [ 47.  32.  27.]]\n",
      "\n",
      "  [[193. 182. 178.]\n",
      "   [189. 178. 174.]\n",
      "   [195. 181. 178.]\n",
      "   ...\n",
      "   [ 46.  31.  26.]\n",
      "   [ 54.  37.  30.]\n",
      "   [ 59.  35.  35.]]\n",
      "\n",
      "  [[190. 179. 175.]\n",
      "   [191. 180. 176.]\n",
      "   [194. 180. 177.]\n",
      "   ...\n",
      "   [ 89.  86.  71.]\n",
      "   [ 52.  47.  28.]\n",
      "   [ 42.  24.  12.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[154. 140. 131.]\n",
      "   [176. 161. 156.]\n",
      "   [182. 168. 159.]\n",
      "   ...\n",
      "   [ 72.  56.  40.]\n",
      "   [ 82.  66.  53.]\n",
      "   [ 73.  65.  46.]]\n",
      "\n",
      "  [[174. 155. 140.]\n",
      "   [161. 145. 132.]\n",
      "   [177. 163. 150.]\n",
      "   ...\n",
      "   [ 74.  53.  36.]\n",
      "   [ 75.  57.  43.]\n",
      "   [ 81.  63.  51.]]\n",
      "\n",
      "  [[182. 166. 153.]\n",
      "   [176. 157. 142.]\n",
      "   [167. 150. 134.]\n",
      "   ...\n",
      "   [ 70.  55.  36.]\n",
      "   [ 72.  54.  44.]\n",
      "   [ 84.  66.  54.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.76862746 0.7254902  0.70980394]\n",
      "   [0.74509805 0.7019608  0.6862745 ]\n",
      "   [0.74509805 0.6901961  0.6784314 ]\n",
      "   ...\n",
      "   [0.16862746 0.11764706 0.08235294]\n",
      "   [0.1882353  0.12156863 0.08235294]\n",
      "   [0.18431373 0.1254902  0.10588235]]\n",
      "\n",
      "  [[0.75686276 0.7137255  0.69803923]\n",
      "   [0.7411765  0.69803923 0.68235296]\n",
      "   [0.7647059  0.70980394 0.69803923]\n",
      "   ...\n",
      "   [0.18039216 0.12156863 0.10196079]\n",
      "   [0.21176471 0.14509805 0.11764706]\n",
      "   [0.23137255 0.13725491 0.13725491]]\n",
      "\n",
      "  [[0.74509805 0.7019608  0.6862745 ]\n",
      "   [0.7490196  0.7058824  0.6901961 ]\n",
      "   [0.7607843  0.7058824  0.69411767]\n",
      "   ...\n",
      "   [0.34901962 0.3372549  0.2784314 ]\n",
      "   [0.20392157 0.18431373 0.10980392]\n",
      "   [0.16470589 0.09411765 0.04705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6039216  0.54901963 0.5137255 ]\n",
      "   [0.6901961  0.6313726  0.6117647 ]\n",
      "   [0.7137255  0.65882355 0.62352943]\n",
      "   ...\n",
      "   [0.28235295 0.21960784 0.15686275]\n",
      "   [0.32156864 0.25882354 0.20784314]\n",
      "   [0.28627452 0.25490198 0.18039216]]\n",
      "\n",
      "  [[0.68235296 0.60784316 0.54901963]\n",
      "   [0.6313726  0.5686275  0.5176471 ]\n",
      "   [0.69411767 0.6392157  0.5882353 ]\n",
      "   ...\n",
      "   [0.2901961  0.20784314 0.14117648]\n",
      "   [0.29411766 0.22352941 0.16862746]\n",
      "   [0.31764707 0.24705882 0.2       ]]\n",
      "\n",
      "  [[0.7137255  0.6509804  0.6       ]\n",
      "   [0.6901961  0.6156863  0.5568628 ]\n",
      "   [0.654902   0.5882353  0.5254902 ]\n",
      "   ...\n",
      "   [0.27450982 0.21568628 0.14117648]\n",
      "   [0.28235295 0.21176471 0.17254902]\n",
      "   [0.32941177 0.25882354 0.21176471]]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 62, 62, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 29, 29, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                100384    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 101,809\n",
      "Trainable params: 101,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(\n",
    "    filters=8,\n",
    "    kernel_size=(3,3),\n",
    "    activation='relu',\n",
    "    input_shape=(64,64,3)\n",
    "))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "output=model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_7/Sigmoid:0', description=\"created by layer 'dense_7'\")\n"
     ]
    }
   ],
   "source": [
    "print(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: DOG\n"
     ]
    }
   ],
   "source": [
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Prediction: DOG\")\n",
    "else:\n",
    "    print(\"Prediction: CAT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
